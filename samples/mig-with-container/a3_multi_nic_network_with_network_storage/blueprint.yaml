# Copyright 2022 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

---

blueprint_name: a3-mig-with-container

vars:
  deployment_name: a3-mig-with-container
  project_id: my-project-id
  resource_prefix: my-cluster-name
  target_size: 1
  zone: us-central1-c

  container:
    cmd: null
    image: gcr.io/deeplearning-platform-release/base-gpu.py310
    run_at_boot: true
    run_options: null
  disk_size_gb: 1024
  disk_type: pd-ssd
  filestore_new:
  - filestore_tier: BASIC_HDD
    local_mount: /mnt/nfsmount
    size_gb: 1024
  gcsfuse_existing:
    - local_mount: /mnt/gcsmount
      remote_mount: my-bucket
  labels:
    purpose: testing
  startup_script: |
    #!/bin/sh -e
    docker-credential-gcr configure-docker
    docker-credential-gcr configure-docker --registries us-docker.pkg.dev

    # Configure the Receive Data Path Manager
    docker run --pull=always --rm \
      --name receive-datapath-manager \
      --detach \
      --cap-add=NET_ADMIN --network=host \
      --volume /var/lib/nvidia/lib64:/usr/local/nvidia/lib64 \
      --device /dev/nvidia0:/dev/nvidia0 \
      --device /dev/nvidia1:/dev/nvidia1 \
      --device /dev/nvidia2:/dev/nvidia2 \
      --device /dev/nvidia3:/dev/nvidia3 \
      --device /dev/nvidia4:/dev/nvidia4 \
      --device /dev/nvidia5:/dev/nvidia5 \
      --device /dev/nvidia6:/dev/nvidia6 \
      --device /dev/nvidia7:/dev/nvidia7 \
      --device /dev/nvidia-uvm:/dev/nvidia-uvm \
      --device /dev/nvidiactl:/dev/nvidiactl \
      --env LD_LIBRARY_PATH=/usr/local/nvidia/lib64 \
      --volume /run/tcpx:/run/tcpx \
      --entrypoint /tcpgpudmarxd/build/app/tcpgpudmarxd \
      us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpx/tcpgpudmarxd \
      --gpu_nic_preset a3vm --gpu_shmem_type fd --uds_path "/run/tcpx"

    # Configure NCCL and GPUDirectTCPX plugin
    docker run --rm \
      --volume /var/lib:/var/lib \
      us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpx/nccl-plugin-gpudirecttcpx \
      install --install-nccl
    mount --bind /var/lib/tcpx /var/lib/tcpx
    mount -o remount,exec /var/lib/tcpx
  wait_for_instance: false

deployment_groups:
- group: primary
  modules:
  - id: a3-mig-with-container
    source: "github.com/GoogleCloudPlatform/ai-infra-cluster-provisioning//terraform/modules/cluster/mig-with-container"
