cluster:
  nNodes: 4
  nodePool: a3-multi-nic
network:
  useTcpx: "yes"
  ncclIfnames: 'eth0'
  ncclPlugin: us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpx/nccl-plugin-gpudirecttcpx-dev:v3.1.7
  rxdmContainer: us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpx/tcpgpudmarxd-dev:v2.0.11
  disablePmtu: "yes"
workload:
  jobTimestamp: 1
  gcsExperimentBucket: pirillo-sct-bucket
  experimentDir: llama2-13b
  gcsDataBucket: litgpt-public-bucket
  dataDir: openwebtext_dataset
  image: us-docker.pkg.dev/gce-ai-infra/litgpt-full/litgpt/litgpt-full:d5d3714-pytorch22-pytorch22 
  modelName: Llama-2-13b-hf
  batchSize: 6
  microBatchSize: 6
  warmupIters: 10
  maxIters: 30
  collectNsysProfile: 'yes' # Set to 'yes' for profiles
  ncclDebugLevel: TRACE