cluster:
  nNodes: 8
  nodePool: np-1
network:
  useTcpx: "yes"
  ncclIfnames: 'eth0'
  ncclPlugin: us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpx/nccl-plugin-gpudirecttcpx-dev:v3.1.6_2023_10_06
  rxdmContainer: us-docker.pkg.dev/gce-ai-infra/gpudirect-tcpx/tcpgpudmarxd-dev:v2.0.9
  disablePmtu: "yes"
workload:
  jobTimestamp: 1 # Must be defined
  gcsExperimentBucket: tejas_gpu # Must be defined
  experimentDir: llama2-7b-8nodes-bs6-original
  gcsDataBucket: litgpt-public-bucket
  dataDir: openwebtext_dataset
  image: us-central1-docker.pkg.dev/supercomputer-testing/tejasnama-gcr/litgpt-full:latest
  modelName: Llama-2-7b-hf
  batchSize: 6
  microBatchSize: 4
  warmupIters: 10
  maxIters: 100
  numBlocksToCombine: 1
  
